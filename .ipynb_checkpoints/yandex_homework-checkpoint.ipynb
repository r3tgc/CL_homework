{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embeddings for ukrainian and russian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_emb = KeyedVectors.load_word2vec_format(\"../cc.uk.300.vec\")#, limit = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_emb = KeyedVectors.load_word2vec_format(\"../cc.ru.300.vec\")#, limit = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Load small dictionaries for correspoinding words pairs as trainset and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('август', 1.0),\n",
       " ('июль', 0.9383152723312378),\n",
       " ('сентябрь', 0.9240028858184814),\n",
       " ('июнь', 0.9222574830055237),\n",
       " ('октябрь', 0.9095539450645447),\n",
       " ('ноябрь', 0.8930035829544067),\n",
       " ('апрель', 0.8729087710380554),\n",
       " ('декабрь', 0.8652557730674744),\n",
       " ('март', 0.8545796871185303),\n",
       " ('февраль', 0.8401415944099426)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('серпень', 1.0),\n",
       " ('липень', 0.9096440076828003),\n",
       " ('вересень', 0.9016969799995422),\n",
       " ('червень', 0.8992519974708557),\n",
       " ('жовтень', 0.8810408115386963),\n",
       " ('листопад', 0.8787633776664734),\n",
       " ('квітень', 0.8592804670333862),\n",
       " ('грудень', 0.8586863279342651),\n",
       " ('травень', 0.8408110737800598),\n",
       " ('лютий', 0.8256431818008423)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Недопустимость', 0.24435284733772278),\n",
       " ('конструктивность', 0.23293080925941467),\n",
       " ('офор', 0.23256802558898926),\n",
       " ('deteydlya', 0.2303171455860138),\n",
       " ('пресечении', 0.22632381319999695),\n",
       " ('одностороннего', 0.22608885169029236),\n",
       " ('подход', 0.22305874526500702),\n",
       " ('иболее', 0.22003725171089172),\n",
       " ('2015Александр', 0.21872764825820923),\n",
       " ('конструктивен', 0.21796569228172302)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_pairs(filename):\n",
    "    uk_ru_pairs = []\n",
    "    uk_vectors = []\n",
    "    ru_vectors = []\n",
    "    with open(filename, \"r\") as inpf:\n",
    "        for line in inpf:\n",
    "            uk, ru = line.rstrip().split(\"\\t\")\n",
    "            if uk not in uk_emb or ru not in ru_emb:\n",
    "                continue\n",
    "            uk_ru_pairs.append((uk, ru))\n",
    "            uk_vectors.append(uk_emb[uk])\n",
    "            ru_vectors.append(ru_emb[ru])\n",
    "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_ru_train, X_train, Y_train = load_word_pairs(\"../ukr_rus.train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_ru_test, X_test, Y_test = load_word_pairs(\"../ukr_rus.test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Embedding space mapping\n",
    "\n",
    "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
    "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
    "\n",
    "or $$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
    "\n",
    "where $||*||_F$ - Frobenius norm.\n",
    "\n",
    "$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604608964938944\n",
      "[[-0.13853334  0.03785874  0.00846561 ...  0.12043508  0.1230209\n",
      "   0.05481485]\n",
      " [ 0.01697174  0.00580407  0.03639334 ...  0.02279952  0.11457596\n",
      "  -0.00381462]\n",
      " [ 0.05413085 -0.05171295  0.04750827 ...  0.05530106  0.06657097\n",
      "  -0.03942306]\n",
      " ...\n",
      " [ 0.01256713 -0.04073871 -0.04768448 ... -0.05323557  0.11357719\n",
      "   0.01744952]\n",
      " [-0.05282985  0.0651894  -0.03701065 ...  0.18449809  0.13728851\n",
      "  -0.12552929]\n",
      " [ 0.00325489 -0.0685897   0.11475997 ... -0.01013895  0.12247851\n",
      "  -0.09955335]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "mapping = LinearRegression().fit(X_train, Y_train)\n",
    "print(mapping.score(X_train, Y_train))\n",
    "print(mapping.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's take a look at neigbours of the vector of word \"серпень\" (\"август\" in Russian) after linear transform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('июнь', 0.857708215713501),\n",
       " ('июль', 0.8437438011169434),\n",
       " ('сентябрь', 0.8341312408447266),\n",
       " ('апрель', 0.8312028646469116),\n",
       " ('октябрь', 0.8284209370613098),\n",
       " ('ноябрь', 0.8258079290390015),\n",
       " ('март', 0.818211555480957),\n",
       " ('август', 0.8082067370414734),\n",
       " ('декабрь', 0.8062343597412109),\n",
       " ('февраль', 0.7984046339988708)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
    "ru_emb.most_similar(august)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('кот', 0.45249590277671814),\n",
       " ('пес', 0.4417025148868561),\n",
       " ('пёс', 0.42835986614227295),\n",
       " ('волк', 0.42355042695999146),\n",
       " ('поросенок', 0.41129735112190247),\n",
       " ('заяц', 0.41038671135902405),\n",
       " ('рыжий', 0.4096396863460541),\n",
       " ('щенок', 0.40759021043777466),\n",
       " ('котик', 0.40626364946365356),\n",
       " ('волчонок', 0.4060942828655243)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar(mapping.predict(uk_emb[\"кіт\"].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place.\n",
    "\n",
    "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(pairs, mapped_vectors, topn=1):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
    "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
    "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
    "    :returns:\n",
    "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
    "    \"\"\"\n",
    "    assert len(pairs) == len(mapped_vectors)\n",
    "    num_matches = 0\n",
    "    for i, (_, ru) in enumerate(pairs):\n",
    "        # YOUR CODE HERE   \n",
    "        mapped_vector = mapped_vectors[i]\n",
    "        if ru in [x for (x,_) in ru_emb.most_similar([mapped_vector],topn=topn)]:\n",
    "            num_matches += 1\n",
    "    precision_val = num_matches / len(pairs)\n",
    "    return precision_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
    "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
    "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert precision(uk_ru_test, X_test) == 0.0\n",
    "assert precision(uk_ru_test, Y_test) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
    "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5461538461538461\n",
      "0.7307692307692307\n"
     ]
    }
   ],
   "source": [
    "print(precision_top1)\n",
    "print(precision_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Making it better (orthogonal Procrustean problem)\n",
    "\n",
    "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal. We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$$$I \\text{- identity matrix}$$\n",
    "\n",
    "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components: $$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$ $$W^*=UV^T$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_transform(X, Y):\n",
    "    \"\"\" \n",
    "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
    "    \"\"\"\n",
    "    # YOU CODE HERE\n",
    "    U, s, V = np.linalg.svd(np.matmul(X_train.T,Y_train))\n",
    "    W = np.matmul(U,V)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = learn_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n",
      "0.7615384615384615\n"
     ]
    }
   ],
   "source": [
    "print(precision(uk_ru_test, np.matmul(X_test, W)))\n",
    "print(precision(uk_ru_test, np.matmul(X_test, W), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "UK-RU Translator\n",
    "\n",
    "Now we are ready to make simple word-based translator: for earch word in source language in shared embedding space we find the nearest in target language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../fairy_tale.txt\", \"r\") as inpf:\n",
    "    uk_sentences = [line.rstrip().lower() for line in inpf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['лисичка - сестричка і вовк - панібрат',\n",
       " 'як була собі лисичка , да й пішла раз до однії баби добувать огню ; ввійшла у хату да й каже : \" добрий день тобі , бабусю !',\n",
       " 'дай мені огня \" .',\n",
       " 'а баба тільки що вийняла із печі пирожок із маком , солодкий , да й положила , щоб він прохолов ; а лисичка се і підгледала , да тілько що баба нахилилась у піч , щоб достать огня , то лисичка зараз ухватила пирожок да і драла з хати , да , біжучи , весь мак із його виїла , а туда сміття наклала .',\n",
       " 'прибігла на поле , аж там пасуть хлопці бичків .',\n",
       " 'вона і каже їм : \" ей , хлопці !',\n",
       " 'проміняйте мені бичка - третячка за маковий пирожок \" .',\n",
       " 'тії согласились ; так вона їм говорить : \" смотріть же , ви не їжте зараз сього пирожка , а тоді уже розломите , як я заведу бичка за могилку ; а то ви його ні за що не розломите \" .',\n",
       " 'бачите вже - лисичка таки собі була розумна , що хоть кого да обманить .',\n",
       " 'тії хлопці так і зробили , а лисичка як зайшла за могилу , да зараз у ліс і повернула , щоб на дорозі не догнали ; прийшла у ліс да і зробила собі санки да й їде .',\n",
       " 'коли йде вовчик : \" здорова була , лисичко - сестричко ! \"',\n",
       " '- \" здоров , вовчику - братику ! \"',\n",
       " '- \" де се ти узяла собі і бичка і санки ? \"',\n",
       " '- \" е !',\n",
       " 'зробила \" .',\n",
       " '- \" підвези ж і мене \" .',\n",
       " '- \" е , вовчику !',\n",
       " 'не можна \" .',\n",
       " '- \" мені хоть одну ніжку \" .',\n",
       " '- \" одну можна \" .',\n",
       " \"він і положив , да од'їхавши немного і просить , щоби іще одну положить .\",\n",
       " '\" не можна , братику !',\n",
       " 'боюсь , щоб ти саней не зламав \" .',\n",
       " '- \" ні , сестричко , не бійся ! \"',\n",
       " '- да і положив другую ніжку .',\n",
       " \"тілько що од'їхали , як щось і тріснуло .\",\n",
       " '\" бачиш , вовчику , уже і ламаєш санки \" .',\n",
       " '- \" ні , лисичко !',\n",
       " 'се у мене був орішок , так я розкусив \" .',\n",
       " \"да просить оп'ять , щоб і третю ногу положить ; лисичка і ту пустила , да тілько що оп'ять од'їхали , аж щось уже дужче тріснуло .\",\n",
       " 'лисичка закричала : \" ох , лишечко !',\n",
       " 'ти ж мені , братику , зовсім зламаєш санки \" .',\n",
       " '- \" ні , лисичко , се я орішок розкусив \" .',\n",
       " '- \" дай же і мені , бачиш який , що сам їж , а мені і не даєш \" .',\n",
       " '- \" нема уже більше , а я б дав \" .',\n",
       " \"да і просить оп'ять , щоб пустила положить і послідню ногу .\",\n",
       " 'лисичка і согласилась .',\n",
       " 'так він тілько що положив ногу , як санки зовсім розламались .',\n",
       " 'тоді вже лисичка так на його розсердилась , що і сама не знала щоб робила !',\n",
       " 'а як отошло серце , вона і каже : \" іди ж , ледащо !',\n",
       " 'да нарубай дерева , щоб нам оп\\'ять ізробить санки ; тільки рубавши кажи так : \" рубайся ж , дерево , і криве і пряме \" .',\n",
       " 'він і пішов да й каже усе : \" рубайся ж , дерево , усе пряме да пряме ! \"',\n",
       " \"нарубавши і приносить ; лисичка увидала , що дерево не таке , як їй нужно , оп'ять розсердилась .\",\n",
       " '\" ти , - говорить , - не казав , видно , так , як я тобі веліла ! \"',\n",
       " '- \" ні , я усе теє казав , що ти мені казала \" .',\n",
       " '- \" да чомусь не таке рубалось ?',\n",
       " 'ну , сиди ж ти тут , а я сама піду нарубаю \" , - да і пішла у ліс .',\n",
       " 'а вовк дивиться , що він сам остався ; узяв да проїв у бичка дірку да виїв усе в середині , а напускав туда горобців да ще соломою заткнув , поставив бичка , а сам і втік .',\n",
       " 'аж лисичка приходить , зробила санки да й сіла і стала поганять : \" гей , бичок - третячок ! \"',\n",
       " 'тілько він не везе .',\n",
       " 'от вона встала , щоб поправить : може , що не так запряжено ; да , не хотячи , одоткнула солому , а оттуда так і сипнули горобці летіти .',\n",
       " 'вона уже тоді побачила , що бичок неживий ; покинула його да й пішла .',\n",
       " 'легла на дорозі , аж дивиться - їде мужик з рибою ; вона і притворилась , що здохла .',\n",
       " 'от мужик і говорить : \" возьму я оцю лисицю , обдеру да хоть шапку собі зошью \" .',\n",
       " 'узяв да і положив ззаді у воза .',\n",
       " \"вона замітила , що мужик не смотрить , стала ногами викидувать рибу з воза , а когда побачила , що навикидала уже багато , тоди потихесеньку і сама злізла ; сіла біля риби да і їсть собі , - коли біжить оп'ять той самий вовчик .\",\n",
       " 'побачивши , що вона їсть рибу , прибіг до їй да й каже : \" здорово була , лисичко - сестричко !',\n",
       " 'де се ти набрала стільки риби ? \"',\n",
       " 'вона каже : \" наловила , вовчику - братику ! \"',\n",
       " 'а собі на думці : \" подожди , і я зроблю з тобою таку штуку , як і ти зо мною \" .',\n",
       " '- \" як же ти ловила ? \"',\n",
       " '- \" так , вовчику , уложила хвостик в ополонку , вожу тихенько да й кажу ; ловися , рибка , мала і велика !',\n",
       " 'коли хочеш , то і ти піди , налови собі \" .',\n",
       " 'він побіг да зробив так , як казала лисичка .',\n",
       " 'а лисичка стала за деревом да й дивиться ; коли у вовчика зовсім хвостик примерз , вона тоді побігла в село да й кричить : \" ідіть , люди , вбивайте вовка ! \"',\n",
       " 'люди набігли з кольями да і убили його .',\n",
       " '']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        sentence - sentence in Ukrainian (str)\n",
    "    :returns:\n",
    "        translation - sentence in Russian (str)\n",
    "\n",
    "    * find ukrainian embedding for each word in sentence\n",
    "    * transform ukrainian embedding vector\n",
    "    * find nearest russian word and replace\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    words = sentence.split(' ')\n",
    "    translation = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            emb = uk_emb[word]\n",
    "            translation.append(ru_emb.most_similar([np.matmul(emb, W)], topn=1)[0][0])           \n",
    "        except:\n",
    "            translation.append(word)\n",
    "    return ' '.join(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хорошо сало со водкой , особенно со перцем\n"
     ]
    }
   ],
   "source": [
    "print(translate(\"добре сало з горілкою , особливо з перцем\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: лисичка - сестричка і вовк - панібрат\n",
      "dst: лисичка — девочка и волк — панібрат\n",
      "\n",
      "src: як була собі лисичка , да й пішла раз до однії баби добувать огню ; ввійшла у хату да й каже : \" добрий день тобі , бабусю !\n",
      "dst: как была себе лисичка , из и пошла раз до однії бабы добувать огнь ; вошла во хату из и говорит : \" хороший день тебе , бабушку !\n",
      "\n",
      "src: дай мені огня \" .\n",
      "dst: дай мне огня \" .\n",
      "\n",
      "src: а баба тільки що вийняла із печі пирожок із маком , солодкий , да й положила , щоб він прохолов ; а лисичка се і підгледала , да тілько що баба нахилилась у піч , щоб достать огня , то лисичка зараз ухватила пирожок да і драла з хати , да , біжучи , весь мак із його виїла , а туда сміття наклала .\n",
      "dst: а баба только что вытащила со печи пирожок со маком , сладкий , из и лежала , чтобы он прохолов ; а лисичка чтó и підгледала , из притом что баба приподнялась во печь , чтобы достать огня , то лисичка сейчас ухватила пирожок из и пустить со хаты , из , пробежать , весь мак со его виїла , а туда мусор наложила .\n",
      "\n",
      "src: прибігла на поле , аж там пасуть хлопці бичків .\n",
      "dst: прибежала по поле , до там пасутся ребята выловленных .\n",
      "\n",
      "src: вона і каже їм : \" ей , хлопці !\n",
      "dst: она и говорит им : \" иэ , ребята !\n",
      "\n",
      "src: проміняйте мені бичка - третячка за маковий пирожок \" .\n",
      "dst: проміняйте мне бычка — третячка за маковый пирожок \" .\n",
      "\n",
      "src: тії согласились ; так вона їм говорить : \" смотріть же , ви не їжте зараз сього пирожка , а тоді уже розломите , як я заведу бичка за могилку ; а то ви його ні за що не розломите \" .\n",
      "dst: они. договорились ; так она им говорит : \" смотріть то , мы не ешьте сейчас сего пирожка , а тогда уже розломите , как мной заведу бычка за могиле ; а то мы его ни за что не розломите \" .\n",
      "\n",
      "src: бачите вже - лисичка таки собі була розумна , що хоть кого да обманить .\n",
      "dst: видишь уже — лисичка все-таки себе была умная , что хоть кого из обманить .\n",
      "\n",
      "src: тії хлопці так і зробили , а лисичка як зайшла за могилу , да зараз у ліс і повернула , щоб на дорозі не догнали ; прийшла у ліс да і зробила собі санки да й їде .\n",
      "dst: они. ребята так и сделали , а лисичка как зашла за могилу , из сейчас во лес и вернула , чтобы по дороге не погнали ; пришла во лес из и сделала себе санки из и едет .\n",
      "\n",
      "src: коли йде вовчик : \" здорова була , лисичко - сестричко ! \"\n",
      "dst: когда идет вовчик : \" здоровая была , лисичко — сестренка ! \"\n",
      "\n",
      "src: - \" здоров , вовчику - братику ! \"\n",
      "dst: — \" здоровье , вовчику — маме ! \"\n",
      "\n",
      "src: - \" де се ти узяла собі і бичка і санки ? \"\n",
      "dst: — \" куда чтó мы взяла себе и бычка и санки ? \"\n",
      "\n",
      "src: - \" е !\n",
      "dst: — \" в. !\n",
      "\n",
      "src: зробила \" .\n",
      "dst: сделала \" .\n",
      "\n",
      "src: - \" підвези ж і мене \" .\n",
      "dst: — \" підвези же и меня \" .\n",
      "\n",
      "src: - \" е , вовчику !\n",
      "dst: — \" в. , вовчику !\n",
      "\n",
      "src: не можна \" .\n",
      "dst: не можно \" .\n",
      "\n",
      "src: - \" мені хоть одну ніжку \" .\n",
      "dst: — \" мне хоть одну ножку \" .\n",
      "\n",
      "src: - \" одну можна \" .\n",
      "dst: — \" одну можно \" .\n",
      "\n",
      "src: він і положив , да од'їхавши немного і просить , щоби іще одну положить .\n",
      "dst: он и положил , из од'їхавши немножко и просит , чтобы еще одну разодрать .\n",
      "\n",
      "src: \" не можна , братику !\n",
      "dst: \" не можно , маме !\n",
      "\n",
      "src: боюсь , щоб ти саней не зламав \" .\n",
      "dst: боюсь , чтобы мы саней не сломал \" .\n",
      "\n",
      "src: - \" ні , сестричко , не бійся ! \"\n",
      "dst: — \" ни , сестренка , не бойся ! \"\n",
      "\n",
      "src: - да і положив другую ніжку .\n",
      "dst: — из и положил одну ножку .\n",
      "\n",
      "src: тілько що од'їхали , як щось і тріснуло .\n",
      "dst: притом что од'їхали , как что-то и треснуло .\n",
      "\n",
      "src: \" бачиш , вовчику , уже і ламаєш санки \" .\n",
      "dst: \" видишь , вовчику , уже и ламаєш санки \" .\n",
      "\n",
      "src: - \" ні , лисичко !\n",
      "dst: — \" ни , лисичко !\n",
      "\n",
      "src: се у мене був орішок , так я розкусив \" .\n",
      "dst: чтó во меня был орішок , так мной розкусив \" .\n",
      "\n",
      "src: да просить оп'ять , щоб і третю ногу положить ; лисичка і ту пустила , да тілько що оп'ять од'їхали , аж щось уже дужче тріснуло .\n",
      "dst: из просит оп'ять , чтобы и третью ногу разодрать ; лисичка и ту пустила , из притом что оп'ять од'їхали , до что-то уже сильней треснуло .\n",
      "\n",
      "src: лисичка закричала : \" ох , лишечко !\n",
      "dst: лисичка закричала : \" Ох , лишечко !\n",
      "\n",
      "src: ти ж мені , братику , зовсім зламаєш санки \" .\n",
      "dst: мы же мне , маме , совсем зламаєш санки \" .\n",
      "\n",
      "src: - \" ні , лисичко , се я орішок розкусив \" .\n",
      "dst: — \" ни , лисичко , чтó мной орішок розкусив \" .\n",
      "\n",
      "src: - \" дай же і мені , бачиш який , що сам їж , а мені і не даєш \" .\n",
      "dst: — \" дай то и мне , видишь какой , что сам ел , а мне и не даешь \" .\n",
      "\n",
      "src: - \" нема уже більше , а я б дав \" .\n",
      "dst: — \" нету уже больше , а мной бы дал \" .\n",
      "\n",
      "src: да і просить оп'ять , щоб пустила положить і послідню ногу .\n",
      "dst: из и просит оп'ять , чтобы пустила разодрать и послідню ногу .\n",
      "\n",
      "src: лисичка і согласилась .\n",
      "dst: лисичка и согласилась .\n",
      "\n",
      "src: так він тілько що положив ногу , як санки зовсім розламались .\n",
      "dst: так он притом что положил ногу , как санки совсем розламались .\n",
      "\n",
      "src: тоді вже лисичка так на його розсердилась , що і сама не знала щоб робила !\n",
      "dst: тогда уже лисичка так по его розсердилась , что и одна не знала чтобы делала !\n",
      "\n",
      "src: а як отошло серце , вона і каже : \" іди ж , ледащо !\n",
      "dst: а как отошло сердце , она и говорит : \" иди же , житьё !\n",
      "\n",
      "src: да нарубай дерева , щоб нам оп'ять ізробить санки ; тільки рубавши кажи так : \" рубайся ж , дерево , і криве і пряме \" .\n",
      "dst: из нарубай деревья , чтобы нам оп'ять ізробить санки ; только рубавши говори так : \" рубайся же , дерево , и кривое и прямое \" .\n",
      "\n",
      "src: він і пішов да й каже усе : \" рубайся ж , дерево , усе пряме да пряме ! \"\n",
      "dst: он и пошел из и говорит всё : \" рубайся же , дерево , всё прямое из прямое ! \"\n",
      "\n",
      "src: нарубавши і приносить ; лисичка увидала , що дерево не таке , як їй нужно , оп'ять розсердилась .\n",
      "dst: нарубавши и приносит ; лисичка увидала , что дерево не такое , как им надо , оп'ять розсердилась .\n",
      "\n",
      "src: \" ти , - говорить , - не казав , видно , так , як я тобі веліла ! \"\n",
      "dst: \" мы , — говорит , — не говорил , видно , так , как мной тебе велела ! \"\n",
      "\n",
      "src: - \" ні , я усе теє казав , що ти мені казала \" .\n",
      "dst: — \" ни , мной всё белу говорил , что мы мне говорила \" .\n",
      "\n",
      "src: - \" да чомусь не таке рубалось ?\n",
      "dst: — \" из почему-то не такое рубалось ?\n",
      "\n",
      "src: ну , сиди ж ти тут , а я сама піду нарубаю \" , - да і пішла у ліс .\n",
      "dst: из , сиди же мы здесь , а мной одна пойду нарубаю \" , — из и пошла во лес .\n",
      "\n",
      "src: а вовк дивиться , що він сам остався ; узяв да проїв у бичка дірку да виїв усе в середині , а напускав туда горобців да ще соломою заткнув , поставив бичка , а сам і втік .\n",
      "dst: а волк смотрит , что он сам остался ; взял из проїв во бычка дыру из виїв всё во середине , а напускав туда птиц из ещe соломой заткнул , поставил бычка , а сам и сбежал .\n",
      "\n",
      "src: аж лисичка приходить , зробила санки да й сіла і стала поганять : \" гей , бичок - третячок ! \"\n",
      "dst: до лисичка приходит , сделала санки из и сесть и стала поганять : \" гей , бычок — третячок ! \"\n",
      "\n",
      "src: тілько він не везе .\n",
      "dst: притом он не едет .\n",
      "\n",
      "src: от вона встала , щоб поправить : може , що не так запряжено ; да , не хотячи , одоткнула солому , а оттуда так і сипнули горобці летіти .\n",
      "dst: из она встала , чтобы решит : может , что не так запряжено ; из , не вздумал , одоткнула солому , а туда так и сипнули воробьи лететь .\n",
      "\n",
      "src: вона уже тоді побачила , що бичок неживий ; покинула його да й пішла .\n",
      "dst: она уже тогда увидела , что бычок неживой ; покинула его из и пошла .\n",
      "\n",
      "src: легла на дорозі , аж дивиться - їде мужик з рибою ; вона і притворилась , що здохла .\n",
      "dst: легла по дороге , до смотрит — едет мужик со рыбой ; она и притворилась , что сдохла .\n",
      "\n",
      "src: от мужик і говорить : \" возьму я оцю лисицю , обдеру да хоть шапку собі зошью \" .\n",
      "dst: из мужик и говорит : \" возьму мной ихнюю лисицу , обдеру из хоть шапку себе зошью \" .\n",
      "\n",
      "src: узяв да і положив ззаді у воза .\n",
      "dst: взял из и положил взади во телеге .\n",
      "\n",
      "src: вона замітила , що мужик не смотрить , стала ногами викидувать рибу з воза , а когда побачила , що навикидала уже багато , тоди потихесеньку і сама злізла ; сіла біля риби да і їсть собі , - коли біжить оп'ять той самий вовчик .\n",
      "dst: она заметила , что мужик не смотрить , стала ногами викидувать рыбу со телеге , а .когда увидела , что навикидала уже много , системы потихесеньку и одна забралась ; сесть возле рыбы из и ест себе , — когда бежит оп'ять тот самый вовчик .\n",
      "\n",
      "src: побачивши , що вона їсть рибу , прибіг до їй да й каже : \" здорово була , лисичко - сестричко !\n",
      "dst: увидев , что она ест рыбу , прибежал до им из и говорит : \" здорово была , лисичко — сестренка !\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: де се ти набрала стільки риби ? \"\n",
      "dst: куда чтó мы набрала столько рыбы ? \"\n",
      "\n",
      "src: вона каже : \" наловила , вовчику - братику ! \"\n",
      "dst: она говорит : \" наловила , вовчику — маме ! \"\n",
      "\n",
      "src: а собі на думці : \" подожди , і я зроблю з тобою таку штуку , як і ти зо мною \" .\n",
      "dst: а себе по мнении : \" подожди , и мной сделаю со тобой такую штуку , как и мы За ней \" .\n",
      "\n",
      "src: - \" як же ти ловила ? \"\n",
      "dst: — \" как то мы ловила ? \"\n",
      "\n",
      "src: - \" так , вовчику , уложила хвостик в ополонку , вожу тихенько да й кажу ; ловися , рибка , мала і велика !\n",
      "dst: — \" так , вовчику , уложила хвостик во прорубь , вожу тихонько из и говорю ; ловися , рыбка , имела и большая !\n",
      "\n",
      "src: коли хочеш , то і ти піди , налови собі \" .\n",
      "dst: когда хочешь , то и мы пойди , налови себе \" .\n",
      "\n",
      "src: він побіг да зробив так , як казала лисичка .\n",
      "dst: он побежал из сделал так , как говорила лисичка .\n",
      "\n",
      "src: а лисичка стала за деревом да й дивиться ; коли у вовчика зовсім хвостик примерз , вона тоді побігла в село да й кричить : \" ідіть , люди , вбивайте вовка ! \"\n",
      "dst: а лисичка стала за деревом из и смотрит ; когда во вовчика совсем хвостик примерз , она тогда побежала во город из и кричит : \" иди , люди , убивайте волка ! \"\n",
      "\n",
      "src: люди набігли з кольями да і убили його .\n",
      "dst: люди убежали со кольями из и убили его .\n",
      "\n",
      "src: \n",
      "dst: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in uk_sentences:\n",
    "    print(\"src: {}\\ndst: {}\\n\".format(sentence, translate(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1, 1'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"1, 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'котик поймал мышь'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"кіт зловив мишу\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : German and French langs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embeddings for French and German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_emb = KeyedVectors.load_word2vec_format(\"../cc.fr.300.vec\",binary=False, limit = 10000)\n",
    "de_emb = KeyedVectors.load_word2vec_format(\"../cc.de.300.vec\",binary=False, limit = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load word pairs (french,german) from .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_pairs(filename):\n",
    "    fr_de_pairs = []\n",
    "    fr_vectors = []\n",
    "    de_vectors = []\n",
    "    \n",
    "    with open(filename, \"r\") as inpf:\n",
    "        for line in inpf:\n",
    "            fr, de = line.rstrip().split(\"\\t\")\n",
    "            if fr not in fr_emb or de not in de_emb:\n",
    "                continue\n",
    "            fr_de_pairs.append((fr, de))\n",
    "            fr_vectors.append(fr_emb[fr])\n",
    "            de_vectors.append(de_emb[de])\n",
    "            \n",
    "    return fr_de_pairs, np.array(fr_vectors), np.array(de_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_de_train, X_train, Y_train = load_word_pairs(\"../fr-de.0-5000.txt\")#(\"../ukr_rus.train.txt\")#\n",
    "de_de_test, X_test, Y_test = load_word_pairs(\"../fr-de.5000-6500.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get two transform matrices M1 and M2 for first 300 pairs and next 300 pairs respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_transform(X, Y):\n",
    "    \"\"\" \n",
    "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
    "    \"\"\"\n",
    "    # YOU CODE HERE\n",
    "    U, s, V = np.linalg.svd(np.matmul(X_train.T,Y_train))\n",
    "    W = np.matmul(U,V)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = learn_transform(X_train[:300], Y_train[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = learn_transform(X_train[300:601], Y_train[300:601])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision for M1 and M2 on different sets of pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(pairs, mapped_vectors, topn=1):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
    "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
    "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
    "    :returns:\n",
    "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
    "    \"\"\"\n",
    "    assert len(pairs) == len(mapped_vectors)\n",
    "    num_matches = 0\n",
    "    for i, (_, ru) in enumerate(pairs):\n",
    "        # YOUR CODE HERE   \n",
    "        mapped_vector = mapped_vectors[i]\n",
    "        if ru in [x for (x,_) in de_emb.most_similar([mapped_vector],topn=topn)]:\n",
    "            num_matches += 1\n",
    "    precision_val = num_matches / len(pairs)\n",
    "    return precision_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair1 M1: 0.8133333333333334\n",
      "pair1 M2: 0.8133333333333334\n",
      "pair2 M1: 0.8803986710963455\n",
      "pair2 M2: 0.8803986710963455\n"
     ]
    }
   ],
   "source": [
    "print(\"pair1 M1: {}\".format(precision(fr_de_train[:300], np.matmul(X_train[:300], M1))))\n",
    "print(\"pair1 M2: {}\".format(precision(fr_de_train[:300], np.matmul(X_train[:300], M2))))\n",
    "print(\"pair2 M1: {}\".format(precision(fr_de_train[300:601], np.matmul(X_train[300:601], M1))))\n",
    "print(\"pair2 M2: {}\".format(precision(fr_de_train[300:601], np.matmul(X_train[300:601], M2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculte Frobenius norm for matrix $|M1-M2|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_M2 = np.linalg.norm((M1-M2),ord='fro')\n",
    "M1_M2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculte $\\frac{|M1-M2|}{|M1|}$ ,where \"$| |$\" is  Frobenius norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_M2/np.linalg.norm(M1,ord='fro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check matrices orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0000001e+00 -3.6554411e-08 -1.5832484e-08 ...  6.1700121e-09\n",
      "   1.4217221e-08 -5.1921234e-08]\n",
      " [-3.6554411e-08  1.0000005e+00  5.5413693e-08 ... -1.2805685e-09\n",
      "  -2.4214387e-08  1.3038516e-08]\n",
      " [-1.5832484e-08  5.5413693e-08  9.9999988e-01 ... -5.8207661e-10\n",
      "  -1.1263182e-08  1.8626451e-08]\n",
      " ...\n",
      " [ 6.1700121e-09 -1.2805685e-09 -5.8207661e-10 ...  9.9999964e-01\n",
      "  -2.5131158e-08  6.8685040e-09]\n",
      " [ 1.4217221e-08 -2.4214387e-08 -1.1263182e-08 ... -2.5131158e-08\n",
      "   9.9999994e-01  3.6423444e-08]\n",
      " [-5.1921234e-08  1.3038516e-08  1.8626451e-08 ...  6.8685040e-09\n",
      "   3.6423444e-08  1.0000004e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(M1,M1.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M1 is orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0000001e+00 -3.6554411e-08 -1.5832484e-08 ...  6.1700121e-09\n",
      "   1.4217221e-08 -5.1921234e-08]\n",
      " [-3.6554411e-08  1.0000005e+00  5.5413693e-08 ... -1.2805685e-09\n",
      "  -2.4214387e-08  1.3038516e-08]\n",
      " [-1.5832484e-08  5.5413693e-08  9.9999988e-01 ... -5.8207661e-10\n",
      "  -1.1263182e-08  1.8626451e-08]\n",
      " ...\n",
      " [ 6.1700121e-09 -1.2805685e-09 -5.8207661e-10 ...  9.9999964e-01\n",
      "  -2.5131158e-08  6.8685040e-09]\n",
      " [ 1.4217221e-08 -2.4214387e-08 -1.1263182e-08 ... -2.5131158e-08\n",
      "   9.9999994e-01  3.6423444e-08]\n",
      " [-5.1921234e-08  1.3038516e-08  1.8626451e-08 ...  6.8685040e-09\n",
      "   3.6423444e-08  1.0000004e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(M2,M2.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M2 is orthogonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same for pairs (German,French)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_pairs(filename):\n",
    "    fr_de_pairs = []\n",
    "    fr_vectors = []\n",
    "    de_vectors = []\n",
    "    \n",
    "    with open(filename, \"r\") as inpf:\n",
    "        for line in inpf:\n",
    "            fr, de = line.rstrip().split(\"\\t\")\n",
    "            if fr not in de_emb or de not in fr_emb:\n",
    "                continue\n",
    "            fr_de_pairs.append((fr, de))\n",
    "            fr_vectors.append(de_emb[fr])\n",
    "            de_vectors.append(fr_emb[de])\n",
    "            \n",
    "    return fr_de_pairs, np.array(fr_vectors), np.array(de_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load word pairs (german,french) from .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_fr_train, X_train, Y_train = load_word_pairs(\"../de-fr.0-5000.txt\")#(\"../ukr_rus.train.txt\")#\n",
    "de_fr_test, X_test, Y_test = load_word_pairs(\"../de-fr.5000-6500.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get two transform matrices M1 and M2 for first 300 pairs and next 300 pairs respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = learn_transform(X_train[:300], Y_train[:300])\n",
    "M2 = learn_transform(X_train[300:601], Y_train[300:601])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision for M1 and M2 on different sets of pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(pairs, mapped_vectors, topn=1):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
    "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
    "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
    "    :returns:\n",
    "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
    "    \"\"\"\n",
    "    assert len(pairs) == len(mapped_vectors)\n",
    "    num_matches = 0\n",
    "    for i, (_, ru) in enumerate(pairs):\n",
    "        # YOUR CODE HERE   \n",
    "        mapped_vector = mapped_vectors[i]\n",
    "        if ru in [x for (x,_) in fr_emb.most_similar([mapped_vector],topn=topn)]:\n",
    "            num_matches += 1\n",
    "    precision_val = num_matches / len(pairs)\n",
    "    return precision_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair1 M1: 0.7533333333333333\n",
      "pair1 M2: 0.7533333333333333\n",
      "pair2 M1: 0.7940199335548173\n",
      "pair2 M2: 0.7940199335548173\n"
     ]
    }
   ],
   "source": [
    "print(\"pair1 M1: {}\".format(precision(de_fr_train[:300], np.matmul(X_train[:300], M1))))\n",
    "print(\"pair1 M2: {}\".format(precision(de_fr_train[:300], np.matmul(X_train[:300], M2))))\n",
    "print(\"pair2 M1: {}\".format(precision(de_fr_train[300:601], np.matmul(X_train[300:601], M1))))\n",
    "print(\"pair2 M2: {}\".format(precision(de_fr_train[300:601], np.matmul(X_train[300:601], M2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculte Frobenius norm for matrix $|M1-M2|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_M2 = np.linalg.norm((M1-M2),ord='fro')\n",
    "M1_M2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculte $\\frac{|M1-M2|}{|M1|}$ ,where \"$| |$\" is  Frobenius norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_M2/np.linalg.norm(M1,ord='fro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check matrices orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.9999976e-01 -3.6321580e-08  4.8428774e-08 ...  4.8894435e-09\n",
      "   3.5157427e-08 -5.4482371e-08]\n",
      " [-3.6321580e-08  1.0000000e+00 -9.3132257e-10 ... -1.7462298e-08\n",
      "  -4.2608008e-08 -1.0186341e-08]\n",
      " [ 4.8428774e-08 -9.3132257e-10  9.9999970e-01 ...  4.5169145e-08\n",
      "  -3.9814040e-08  6.9790985e-08]\n",
      " ...\n",
      " [ 4.8894435e-09 -1.7462298e-08  4.5169145e-08 ...  1.0000000e+00\n",
      "   1.2805685e-09 -3.1956006e-08]\n",
      " [ 3.5157427e-08 -4.2608008e-08 -3.9814040e-08 ...  1.2805685e-09\n",
      "   1.0000000e+00  1.8917490e-09]\n",
      " [-5.4482371e-08 -1.0186341e-08  6.9790985e-08 ... -3.1956006e-08\n",
      "   1.8917490e-09  1.0000004e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(M1,M1.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M1 is orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.9999976e-01 -3.6321580e-08  4.8428774e-08 ...  4.8894435e-09\n",
      "   3.5157427e-08 -5.4482371e-08]\n",
      " [-3.6321580e-08  1.0000000e+00 -9.3132257e-10 ... -1.7462298e-08\n",
      "  -4.2608008e-08 -1.0186341e-08]\n",
      " [ 4.8428774e-08 -9.3132257e-10  9.9999970e-01 ...  4.5169145e-08\n",
      "  -3.9814040e-08  6.9790985e-08]\n",
      " ...\n",
      " [ 4.8894435e-09 -1.7462298e-08  4.5169145e-08 ...  1.0000000e+00\n",
      "   1.2805685e-09 -3.1956006e-08]\n",
      " [ 3.5157427e-08 -4.2608008e-08 -3.9814040e-08 ...  1.2805685e-09\n",
      "   1.0000000e+00  1.8917490e-09]\n",
      " [-5.4482371e-08 -1.0186341e-08  6.9790985e-08 ... -3.1956006e-08\n",
      "   1.8917490e-09  1.0000004e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(M2,M2.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M2 is orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
